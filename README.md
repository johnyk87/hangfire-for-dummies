# Hangfire for Dummies

Anyone who has worked with Hangfire has probably been faced with some tricky requirements like ensuring a job is never executed more than once, or even something more basic like ensuring a job is retried after a server crashes.

A Google search for a way to solve any such requirement usually leads to a rabbit hole of possible configurations, and attributes, and other stuff that we can use to achieve the goal. But each one of those things usually has some other unexpected side-effects, resulting in a massive confusion.

This project is a simple Hangfire test project to help understand exactly how certain "nobs" affect the job execution.

## What is covered here?

This project covers the following features:
* MongoDB storage `InvisibilityTimeout` option.
* Server `WorkerCount` option.
* `AutomaticRetry` job attribute.
* `DisableConcurrentExecution` job attribute.

Please be advised that the existence and behavior of some of these features depends on the storage system used. This project uses MongoDB as the storage engine, just because it is what I used at work at the time I did all of this.

## How to get started?

Easy, start with executing the command `docker-compose up -d` to start up the MongoDB container. Then go into the solution, and play around with the parameters identified with `TODO: play with me!`.

## Too lazy? Then here are some results for some of the tests I already attempted.

|  Id | Scenario                                      | Servers | `BackgroundJobServerOptions` `WorkerCount` | `MongoStorageOptions` `InvisibilityTimeout` | `DisableConcurrentExecution` Timeout | `AutomaticRetry` `Attempts` | Job Execution Time | Results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
|----:|:----------------------------------------------|--------:|-------------------------------------------:|--------------------------------------------:|-------------------------------------:|----------------------------:|-------------------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|   1 | TimeoutJob                                    |       1 |                                          1 |                                        120s |                                  30s |                           2 |                60s | Executes job 3 times before marking it as failed. There is a random back-off period between attempts.                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
|   2 | TimeoutJob x2                                 |       1 |                                          1 |                                        120s |                                  30s |                           2 |                60s | Executes jobs 3 times before marking them as failed. Executions are done one job at a time, i.e., job 1 attempt 1, job 2 attempt 1, job 1 attempt 2, job 2 attempt 2, job 1 attempt 3, job 2 attempt 3.                                                                                                                                                                                                                                                                                                                                                 |
|   3 | TimeoutJob x2                                 |       1 |                                          2 |                                        120s |                                  30s |                           2 |                60s | Job 1 starts executing on first available worker, and job 2 is immediately assigned to second worker. After the `DisableConcurrentExecution` timeout, the job 2 throws a distributed lock exception, and its retry is scheduled. When job 1 exits with its own timeout, it’s retry is also scheduled. Jobs then continue to fight each other for the distributed lock over the course of the remaining attempts, with random success due to the random back-off period of the retries. After all attempts are exhausted, the jobs are marked as failed. |
|   4 | TimeoutJob x2                                 |       1 |                                          2 |                                        120s |                                  90s |                           2 |                60s | Job 1 starts executing on first available worker, and job 2 is immediately assigned to second worker. After job 1 exits with its own timeout, the retry is scheduled, and the job 2 starts executing. When job 2 exits with its own timeout, its retry is also rescheduled. After all attempts are exhausted, the jobs are marked as failed. No distributed lock exception occurs, but it is likely to happen if we increase the amount of queued jobs and workers.                                                                                     |
|   5 | TimeoutJob x2                                 |       2 |                                          1 |                                        120s |                                  90s |                           2 |                60s | Similar behavior to scenario 4 (with one instance and two workers). The concurrent lock applies to all instances.                                                                                                                                                                                                                                                                                                                                                                                                                                       |
|   6 | TimeoutJob + OtherTimeoutJob                  |       1 |                                          2 |                                        120s |                                  90s |                           2 |                60s | Both jobs start immediately. The job’s type is a factor in the concurrent lock. Timeouts in each job are followed by retries being scheduled until they are exhausted and the jobs are marked as failed.                                                                                                                                                                                                                                                                                                                                                |
|   7 | TimeoutJob                                    |       1 |                                          1 |                                        120s |                                  90s |                           2 |               180s | Job exits with its own timeout, and retry is scheduled. After all attempts are exhausted, the job is marked as failed. The concurrent execution timeout is never triggered.                                                                                                                                                                                                                                                                                                                                                                             |
|   8 | TimeoutJob                                    |       1 |                                          2 |                                        120s |                                  90s |                           2 |               180s | Job is canceled after the invisibility timeout, and job is re-queued immediately. This re-queue does not increment the retry count. The concurrent execution timeout is never triggered.                                                                                                                                                                                                                                                                                                                                                                |
|   9 | TimeoutJob                                    |       2 |                                          1 |                                        120s |                                  90s |                           2 |               180s | Similar behavior to scenario 8, but the job is run on different servers on alternate executions. The concurrent execution timeout is never triggered.                                                                                                                                                                                                                                                                                                                                                                                                   |
|  10 | TimeoutJob + server crash + server restart    |       1 |                                          2 |                                        null |                                  90s |                           2 |              3600s | Job is terminated but is never re-queued after the crashed server starts up. It requires manual action to re-queue or delete.                                                                                                                                                                                                                                                                                                                                                                                                                           |
|  11 | TimeoutJob + server restart (ordered)         |       1 |                                          1 |                                        120s |                                  30s |                           2 |                60s | Job is canceled upon shutdown, and is re-queued after restart immediately after startup. This re-queue does not increment the retry count.                                                                                                                                                                                                                                                                                                                                                                                                              |
|  12 | TimeoutJob + server restart (ordered)         |       2 |                                          1 |                                        120s |                                  30s |                           2 |                60s | Job is canceled upon shutdown, and is re-queued on the other server immediately. This re-queue does not increment the retry count.                                                                                                                                                                                                                                                                                                                                                                                                                      |
|  13 | TimeoutJob + server crash + server restart    |       1 |                                          1 |                                        120s |                                  30s |                           2 |                60s | Job is re-queued on the same server after invisibility timeout. This re-queue does not increment the retry count.                                                                                                                                                                                                                                                                                                                                                                                                                                       |
|  14 | TimeoutJob + server crash                     |       2 |                                          1 |                                        120s |                                  30s |                           2 |                60s | Job is re-queued on the other server after invisibility timeout. This re-queue does not increment the retry count.                                                                                                                                                                                                                                                                                                                                                                                                                                      |
|  15 | TimeoutJob x2                                 |       1 |                                          2 |                                        120s |                                   0s |                           2 |                60s | Similar behavior to scenario 3, but job 2 triggers the `DisableConcurrentExecution` timeout immediately after being assigned to a worker.                                                                                                                                                                                                                                                                                                                                                                                                               |
|  16 | TimeoutJob x2 + server restart (ordered)      |       1 |                                          2 |                                        120s |                                  30s |                           2 |                60s | Job 1 starts executing on first available worker, and job 2 is immediately assigned to second worker. After the shutdown signal, job 1 is canceled, and job 2 starts executing with an already canceled token, so it exits immediately as well. Both jobs are re-queued and started when the server restarts. These re-queues do not increment the retry counts.                                                                                                                                                                                        |
|  17 | TimeoutJob x2 + server crash + server restart |       1 |                                          2 |                                        120s |                                  30s |                           2 |                60s | Both jobs are re-queued on the same server after invisibility timeout. This re-queue does not increment the retry count.                                                                                                                                                                                                                                                                                                                                                                                                                                |
|  18 | TimeoutJob                                    |       1 |                                          1 |                                        120s |                                  30s |                        none |                60s | Job exits with its own timeout, and retry is scheduled. A default of 10 retries is considered.                                                                                                                                                                                                                                                                                                                                                                                                                                                          |

## What I know now after all of this.

### MongoDB storage `InvisibilityTimeout` option

* Controls how long any job on the system can be running before it is considered dead.
* If a job is still running, its cancellation token will be triggered when this timeout expires.
* This can be used to ensure that jobs are run again after a server crash during their execution.
* In order to have any impact, there must be an available worker to be checking for jobs to execute.
* This option is storage implementation specific. Different storage types may have different options similar to this, but with different behaviors.
* In the MongoDB version this option is null by default, meaning that jobs will never be re-queued after an unexpected crash.
* In some versions of the SQL Server storage, a similar option has a default timeout of 30 minutes.

### Server `WorkerCount` option.

* The number of parallel jobs that can be executed per server.
* The behavior of other features may be affected by the number of available workers. For instance: the invisibility timeout is only applied when a worker is looking for a job to process; the concurrent execution timeouts will start counting from the moment when an available worker picks up a queued job; etc.
* Having `X` workers in one instance is similar in scheduling and queuing behavior to having `X` servers with 1 worker each.

### `AutomaticRetry` job attribute.

* Controls retry behaviors of a job.
* This is applied using an attribute on the job entry method.
* This is applied to the job instance, i.e., two jobs (different ids) of the same type will each have their retry state (e.g.: attempt count).
* It has multiple options, but the most important is the `Attempts` property, which controls the number of retries that will be executed. The default value is 10 attempts.
* The number of attempts is on top of the initial failed attempt, i.e., with `Attempts = 2` a job may be executed a total of 3 times.
* There are also options to control the delay time between retries. The default behavior is to schedule retries with a random function of the attempt number.
* The retry feature is enabled by default, even without the attribute, using the default settings and behaviors, so this attribute is not required if the default retry settings serve our purpose.
* When jobs are cancelled because of a server being shutdown, they will be re-queued, but that won't be considered a retry and won't count towards the number of attempts.
* When jobs are terminated because of a server crash, they may be re-queued given the invisibility timeout feature, but that won't be considered a retry and won't count towards the number of attempts.

### `DisableConcurrentExecution` job attribute.

* Applies a distributed lock to the job type, based on the job class and entry method names.
* Different job instances that use the same type and method will be exclusive, regardless of job id and parameters.
* This lock applies to all workers on all servers connected to the same data store.
* If there are available workers on any server, they can pick up a queued job and that will immediately start the distributed lock timeout.
* When a distributed lock timeout expires, a distributed lock timeout exception will be thrown and the affected job will be considered as if it failed during execution.
* When a distributed lock exception is thrown, the job will be retried if there are automatic retries enabled and the retry count was not reached yet.
* The distributed lock behavior may differ across different storage implementations.

## Now what?

Well, now feel free to play around with this whenever you want to see how those "nobs" work together.

I hope it helps someone else find the right setup for their scenario.
